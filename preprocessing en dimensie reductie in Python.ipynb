{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# title: \"Preprocessing en dimensie reductie met behulp van Python\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inleiding.\n",
    "\n",
    "Een van de belangrijkste aspecten in wetenschap is om modellen te ontwikkelen die zo éénvoudig mogelijk zijn. Hoe minder variabelen we nodig hebben om accuraat een bepaald gegeven te voorspellen hoe beter. Het maakt ons model eenvoudiger en bovendien kunnen we zo ook overfitting voorkomen.\n",
    "Ook zal onze data in real life veel ongeldige of niet-ingevulde velden kennen. \n",
    "\n",
    "In dit hoofdstuk zullen we verschillende technieken bekijken om dimensie reductie zo ver mogelijk door te drijven.\n",
    "\n",
    "## Aantal dimensies en eerste inspectie van de data\n",
    "\n",
    "### Eerste inspectie: Shape, dtypes, describe, head \n",
    "\n",
    "We onderstellen dat we gegevens zijn ingeladen in een pandas dataframe df.\n",
    "In deze dataframe zorgen we er eerst voor dat de kolommen overeenkomen met de variabelen. Stel dat in onderstaande dataframe a,b,c de variabelen zijn die de vector y moeten voorspellen.\n",
    "\n",
    "Gebruik in Python de volgende code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b  c\n",
      "0  1   2  3\n",
      "1  2   5  6\n",
      "2  7   8  9\n",
      "3  1  11  3\n",
      "4  4   5  6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df2 = pd.DataFrame(np.array([[1, 2, 3], [2, 5, 6], [7, 8, 9],[1, 11, 3],[4, 5, 6]]),columns=['a', 'b', 'c'])\n",
    "print(df2)\n",
    "df2.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De pandas tabel of dataframe bevat hier 3 kolommen en 5 rijen. M.b.v. het shape attribuut kunnen we dit onmiddelijk zien. Het aantal kolommmen geeft eigenlijk het aantal variabelen (ook wel dimensie genoemd) van onze dataset weer. Om te weten welke kolommen er in onze dataframe staan gebruiken we:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a', 'b', 'c'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een eerste idee van de variabelen krijgen we door de beschrijving op te vragen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>5.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.54951</td>\n",
       "      <td>3.420526</td>\n",
       "      <td>2.50998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             a          b        c\n",
       "count  5.00000   5.000000  5.00000\n",
       "mean   3.00000   6.200000  5.40000\n",
       "std    2.54951   3.420526  2.50998\n",
       "min    1.00000   2.000000  3.00000\n",
       "25%    1.00000   5.000000  3.00000\n",
       "50%    2.00000   5.000000  6.00000\n",
       "75%    4.00000   8.000000  6.00000\n",
       "max    7.00000  11.000000  9.00000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een andere nuttig commando is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    int64\n",
      "b    int64\n",
      "c    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In het voorbeeld df2 gaat het om een kleine tabel. De tabel kan echter meer dan duizenden rijen bevatten en honderden kolommen. Om toch een idee the hebben van het soort gegevens dat er in de tabel staat is het goed om de eerste 5 rijen te bekijken. Dit doen we door de methode head() toe te passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name mfr type  calories  protein  fat  sodium  fiber  \\\n",
      "0                   100% Bran   N    C        70        4    1     130   10.0   \n",
      "1           100% Natural Bran   Q    C       120        3    5      15    2.0   \n",
      "2                    All-Bran   K    C        70        4    1     260    9.0   \n",
      "3   All-Bran with Extra Fiber   K    C        50        4    0     140   14.0   \n",
      "4              Almond Delight   R    C       110        2    2     200    1.0   \n",
      "..                        ...  ..  ...       ...      ...  ...     ...    ...   \n",
      "72                    Triples   G    C       110        2    1     250    0.0   \n",
      "73                       Trix   G    C       110        1    1     140    0.0   \n",
      "74                 Wheat Chex   R    C       100        3    1     230    3.0   \n",
      "75                   Wheaties   G    C       100        3    1     200    3.0   \n",
      "76        Wheaties Honey Gold   G    C       110        2    1     200    1.0   \n",
      "\n",
      "    carbo  sugars  potass  vitamins  shelf  weight  cups     rating  \n",
      "0     5.0       6     280        25      3     1.0  0.33  68.402973  \n",
      "1     8.0       8     135         0      3     1.0  1.00  33.983679  \n",
      "2     7.0       5     320        25      3     1.0  0.33  59.425505  \n",
      "3     8.0       0     330        25      3     1.0  0.50  93.704912  \n",
      "4    14.0       8      -1        25      3     1.0  0.75  34.384843  \n",
      "..    ...     ...     ...       ...    ...     ...   ...        ...  \n",
      "72   21.0       3      60        25      3     1.0  0.75  39.106174  \n",
      "73   13.0      12      25        25      2     1.0  1.00  27.753301  \n",
      "74   17.0       3     115        25      1     1.0  0.67  49.787445  \n",
      "75   17.0       3     110        25      1     1.0  1.00  51.592193  \n",
      "76   16.0       8      60        25      1     1.0  0.75  36.187559  \n",
      "\n",
      "[77 rows x 16 columns]\n",
      "name         object\n",
      "mfr          object\n",
      "type         object\n",
      "calories      int64\n",
      "protein       int64\n",
      "fat           int64\n",
      "sodium        int64\n",
      "fiber       float64\n",
      "carbo       float64\n",
      "sugars        int64\n",
      "potass        int64\n",
      "vitamins      int64\n",
      "shelf         int64\n",
      "weight      float64\n",
      "cups        float64\n",
      "rating      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cereals=pd.read_csv('Desktop/datascience/datasets/cereal.csv')\n",
    "print(cereals)\n",
    "print(cereals.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De kolommen kunnen van verschillend type zijn:\n",
    "\n",
    "object:string/gemengde types\n",
    "int64:integer\n",
    "float64:float\n",
    "maar ook belangrijk zijn datetime64(of timedelta):datumtijd variabele\n",
    "\n",
    "Het is belangrijk dat we nakijken of de kolommen van het juiste type zijn.\n",
    "Soms moeten we het data type van een kolom wijzigen.\n",
    "Stel dat we een dataframe df3 hebben en kolom 'lengte' heeft datatype object doch we zien dat er staat 7.1, 8.1,3.2,.... in de kolom. We kunnen dan het type wijzigen als volgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lengte breedte hoogte\n",
      "0     1.0       2      3\n",
      "1     2.0       5      6\n",
      "2     7.0       8      9\n",
      "3     1.0      11      3\n",
      "4     NaN    None   None\n",
      "lengte     float64\n",
      "breedte     object\n",
      "hoogte      object\n",
      "dtype: object\n",
      "------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      "lengte     4 non-null float64\n",
      "breedte    4 non-null object\n",
      "hoogte     4 non-null object\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 248.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "df3 = pd.DataFrame(np.array([[1, 2, 3], [2, 5, 6], [7, 8, 9],[1, 11, 3],[None,None,None]]),columns=['lengte', 'breedte', 'hoogte'])\n",
    "df3['lengte']=df3['lengte'].astype(\"float\")\n",
    "print(df3)\n",
    "print(df3.dtypes)\n",
    "print('------')\n",
    "# PS: de info methode geeft ons meer informatie dan het dtypes attribuut, het geeft ook weer welke waarden er niet null zijn \n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we de rijen willen schrappen waar minstens 1 variabele ontbreekt kunnen we df.dropna() gebruiken.\n",
    "Axis duidt erop of we rijen al dan niet kolommen willen schrappen. De how parameter staat standaard op any (minstens 1 null waarde). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lengte breedte hoogte  gewicht\n",
      "0     1.0       2      3      2.0\n",
      "1     2.0       5      6      NaN\n",
      "2     7.0       8      9      2.0\n",
      "3     1.0      11      3      3.0\n",
      "4     NaN    None   None      NaN\n"
     ]
    }
   ],
   "source": [
    "df3['gewicht']=[2, None , 2, 3, None ]\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In grote dataframe is het niet gemakkelijk om na te gaan waar de NaN staan en hoeveel er zijn. We kunnen gerbuik maken van de isna() methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lengte</th>\n",
       "      <th>breedte</th>\n",
       "      <th>hoogte</th>\n",
       "      <th>gewicht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lengte  breedte  hoogte  gewicht\n",
       "0   False    False   False    False\n",
       "1   False    False   False     True\n",
       "2   False    False   False    False\n",
       "3   False    False   False    False\n",
       "4    True     True    True     True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.isna() # we krijgen een mooi overzicht waar de fouten staan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lengte     1\n",
       "breedte    1\n",
       "hoogte     1\n",
       "gewicht    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.isna().sum() #geeft aan hoeveel waarden er ontbreken voor iedere kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lengte breedte hoogte  gewicht\n",
      "0     1.0       2      3      2.0\n",
      "1     2.0       5      6      NaN\n",
      "2     7.0       8      9      2.0\n",
      "3     1.0      11      3      3.0\n",
      "4     NaN    None   None      NaN\n",
      "   lengte breedte hoogte  gewicht\n",
      "0     1.0       2      3      2.0\n",
      "1     2.0       5      6      NaN\n",
      "2     7.0       8      9      2.0\n",
      "3     1.0      11      3      3.0\n",
      "4     NaN    None   None      NaN\n",
      "   lengte breedte hoogte  gewicht\n",
      "0     1.0       2      3      2.0\n",
      "2     7.0       8      9      2.0\n",
      "3     1.0      11      3      3.0\n",
      "   lengte breedte hoogte  gewicht\n",
      "0     1.0       2      3      2.0\n",
      "2     7.0       8      9      2.0\n",
      "3     1.0      11      3      3.0\n"
     ]
    }
   ],
   "source": [
    "df4=df3.dropna(axis=1,how='all')\n",
    "df5=df3.dropna(axis=0)\n",
    "df6=df3.dropna()\n",
    "print(df3)\n",
    "print(df4)# niks wordt geschrapt want geen enkele kolom bevat allemaal NaN\n",
    "print(df5)# rij 1 en rij 4 bevatten minstens 1 NaN of None\n",
    "print(df6)# standaard is axis=0 en how='any'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een alternatief voor het droppen van een waarde is om de NaN te vervangen door een andere waarde, bijvoorbeeld 0 of een gemiddelde waarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lengte</th>\n",
       "      <th>breedte</th>\n",
       "      <th>hoogte</th>\n",
       "      <th>gewicht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lengte  breedte  hoogte  gewicht\n",
       "0     1.0        2       3      2.0\n",
       "1     2.0        5       6      0.0\n",
       "2     7.0        8       9      2.0\n",
       "3     1.0       11       3      3.0\n",
       "4     0.0        0       0      0.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.fillna(0) #we vervangen de ontbrekende waarden door nul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wijzigen.\n",
    "\n",
    "In de praktijk zijn de ontbrekende waarden niet steeds ingevuld als een NaN of None waarde. In de dataset kan er bijvoorbeeld staan code 7 betekent 'niet ingevuld' en code 8 betekent 'weigert te antwoorden'. In beide gevallen dienen we de code 7 en 8 te vervangen door NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een andere de reden dat men de data wil wijzigen kan bijvoorbeeld zijn dat het antwoord op een vraag is gecodeerd als bijvoorbeeld 'Ja' of Nee' of 1 of 2. Het kan nodig zijn voor sommige analyses dat we dichotome variabelen hercoderen als 1 of 0 (bijvoorbeeld 'ja' als 1 en 'Neen' als 0). Hoe kunnen we dit doen?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In andere gevallen kan het ook zijn dat we een string willen omzetten naar een geheel getal of een float-type. Stel dat de bedragen staan in dollar met het dollar teken naast het cijfer zoals bijvoorbeeld bij 200$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       naam prijs  aantal\n",
      "0  SSDkaart  100$       5\n",
      "1       CPU  300$       1\n",
      "2       GPU  120$       1\n"
     ]
    }
   ],
   "source": [
    "# voorbeeld een dataframe met \n",
    "import pandas as pd\n",
    "df4=pd.DataFrame([['SSDkaart','100$',5],['CPU','300$',1],['GPU','120$',1]],columns=['naam','prijs','aantal'])\n",
    "print(df4.head())                                                 \n",
    "                                                      \n",
    "                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het omzetten van de variabele prijs naar int-type of float-type gaat niet zomaar we moeten hier eerst het dollar teken wegstrippen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       naam  prijs  aantal\n",
      "0  SSDkaart    100       5\n",
      "1       CPU    300       1\n",
      "2       GPU    120       1\n"
     ]
    }
   ],
   "source": [
    "df4['prijs']=df4['prijs'].str.strip('$')\n",
    "# vervolgens kunnen we de string converteren\n",
    "df4['prijs']=df4['prijs'].astype(int)\n",
    "print(df4.head()) \n",
    "# we gaan na met een assert statement dat ale waarden nu int zijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we kunnen het type "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variabelen zonder invloed\n",
    "\n",
    "Wanneer weten we dat een variabele geen invloed zal hebben op onze doelvector y?\n",
    "\n",
    "    Als de waarde voor iedere waarneming dezelfde is\n",
    "    Als de waarde voor iedere waarneming onbekend is\n",
    "\n",
    "Hoe kunnen we dit zien?\n",
    "Als de waarde voor iedere waarneming dezelfde is\n",
    "\n",
    "Voor numerieke gegevens is dit gemakkelijk te achterhalen als voor variabele a std(a)=0 dan is a constant.\n",
    "\n",
    "df.describe() geeft van ieder variabele de mean,std,... als dus std =0 dan kunnen we deze variabele droppen uit de dataframe.\n",
    "\n",
    "Voor niet numerieke waarden zoals categoriën. Kunnen we dit opmerken door van deze gegevens in een histogram af te drukken. Bijvoorbeeld hieronder is c een nutteloos kenmerk omdat iedere rij voor c dezelfde waarde heeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b  c\n",
      "0  1   2  3\n",
      "1  2   5  3\n",
      "2  7   8  3\n",
      "3  1  11  3\n",
      "4  4   5  3\n",
      "             a          b    c\n",
      "count  5.00000   5.000000  5.0\n",
      "mean   3.00000   6.200000  3.0\n",
      "std    2.54951   3.420526  0.0\n",
      "min    1.00000   2.000000  3.0\n",
      "25%    1.00000   5.000000  3.0\n",
      "50%    2.00000   5.000000  3.0\n",
      "75%    4.00000   8.000000  3.0\n",
      "max    7.00000  11.000000  3.0\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.array([[1, 2, 3], [2, 5, 3], [7, 8, 3],[1, 11, 3],[4, 5, 3]]),columns=['a', 'b', 'c'])\n",
    "print(df2)\n",
    "df2.shape\n",
    "print(df2.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Als de waarde voor iedere waarneming onbekend is\n",
    "\n",
    "df.isna().sum() geeft voor iedere kolom in df het aantal waarden waarvoor er geen waarde is gedefinieerd.\n",
    "\n",
    "#### Wat als bijna aan beide voorwaarden is voldaan?\n",
    "\n",
    "Indien aan 1 of beide voorwaarden bijna voldaan is dan zullen we zelf moeten beoordelen of we de variabele verwijderen of niet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a     b     c\n",
      "0  1     2  None\n",
      "1  2     5  None\n",
      "2  7  None  None\n",
      "3  1    11  None\n",
      "4  4     5  None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a    0\n",
       "b    1\n",
       "c    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.array([[1, 2, 3], [2, 5, 3], [7, None, 3],[1, 11, 3],[4, 5, 3]]),columns=['a', 'b', 'c'])\n",
    "df2.c=[None,None,None,None,None]\n",
    "print(df2)\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Gecorreleerde variabelen\n",
    "\n",
    "Een andere reden om variabele te verwijderen is correlatie. Bijvoorbeeld stel dat we het gewicht in kg en het gewicht \n",
    "in ponden hebben van een persoon. Uiteraard zal één variabele voldoende zijn en zal men 1 van de 2 mogen schrappen.\n",
    "\n",
    "Nu hoeft de correlatie niet zo sterk te zijn als hierboven, maar gaat men bij 2 sterk gecorreleerde gegevens met een \n",
    "correlatie coefficient r waarvoor geldt dat abs(r) bijna 1, één van de twee verwijderen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b  c\n",
      "0  1   2  3\n",
      "1  2   5  6\n",
      "2  7   8  9\n",
      "3  1  11  3\n",
      "4  4   5  6\n",
      "          a         b         c\n",
      "a  1.000000  0.172005  0.937614\n",
      "b  0.172005  1.000000  0.104828\n",
      "c  0.937614  0.104828  1.000000\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.array([[1, 2, 3], [2, 5, 6], [7, 8, 9],[1, 11, 3],[4, 5, 6]]),columns=['a', 'b', 'c'])\n",
    "print(df2)\n",
    "print(df2.corr())# we zien tussen a en c een sterke correlatie \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hoe Train-test-split gebruiken?\n",
    "\n",
    "Bij iedere analyse zullen we de dataset opsplitsen in een gedeelte om ons model te trainen (X_train en Y_train) en \n",
    "een ander deel gebruiken we om te kijken hoe goed ons model het doet op nieuwe data (X_test en y_test of test data)\n",
    "\n",
    "Indien de y waarden bestaan uit slechts 2 labels bijvoorbeeld 'ja' en 'neen' dan willen we in de training en de test\n",
    "data dezelfde verhouding terug zien van 'ja' en 'neen' waarden. Dit noemen we gestratifieerd splitsen. Door de \n",
    "volgende instructie zorgt Python dat de y_test en y_train data dus een zelfde verhouding aan 'ja/neen' waarden hebben.\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, stratify=y)\n",
    "\n",
    "### Normalisatie en standarisatie van de gegevens\n",
    "\n",
    "#### Standarddeviatie op 1 zetten en gemiddelde op nul\n",
    "\n",
    "Het kan voor veel analyses die we op de data willen loslaten een voordeel zijn dat de gegevens allemaal gemiddelde nul hebben en standaardafwijking 1. De StandardScaler is de klasse die methodes heeft om dit voor ieder numeriek kenmerk te bewerkstelligen. Het is een klasse die behoort tot  sklearn.preprocessing.\n",
    "\n",
    "\n",
    "#### Log normalizatie\n",
    "\n",
    "Door de natuurlijke logaritme te nemen van een getal kunnen we de variantie van de gegevens sterk verminderen. Opgepast we kunnen dit enkel toepassen op positieve getallen.\n",
    "\n",
    "#### Niet-numerieke gegevens preprocessen.\n",
    "\n",
    "Niet numerieke gegevens zoals tekst willen we graag toch omzetten in numerieke waarden, omdat we dan meer tools kunnen gebruiken om deze gegevens te verwerken.\n",
    "\n",
    "Dit kan gebeuren op verschillende manieren\n",
    "\n",
    "Bijvoorbeeld:\n",
    "\n",
    "Stel dat we dataframe hebben met daarin verschillende kleuren.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Regularisatie\n",
    "\n",
    "### LogisticRegression and RFE\n",
    "\n",
    "### RandomForestClassifier and RFE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Lasso\n",
    "\n",
    "Lasso (Least Absolute Shrinkage and Selection Operator) bespreken. \n",
    "Voor welke alpha is de R^2 optimaal?\n",
    "Zoek evenwicht tussen aantal variabelen en score!\n",
    "\n",
    "LassoCv laat toe om automatisch optimale alpha te bepalen\n",
    "\n",
    "### Elastic Net\n",
    "\n",
    "Probeert nadaelen van Lasso op te heffen. Welke zijn dit?\n",
    "\n",
    "### Wegstemmen van variabelen\n",
    "Met RandomForestRegression\n",
    "Lasso\n",
    "SGRegressor kunnen we variabele selecteren die in de 3 modellen van belang zijn. Wat is de performantie?\n",
    "\n",
    "\n",
    "### Kenmerken extractie (Feature extraction)\n",
    "\n",
    "I.p.v. kenmerken te schrappen kunnen we ook kenmerken combineren.\n",
    "\n",
    "Bijvoorbeeld indien we het kenmerk zwaarlijvigheid willen gebruiken bij het analyseren van de gegevens. Kunnen we de kenmerken lichaamslengte en gewicht combineren in de BMI.\n",
    "\n",
    "De BMI is een kenmerk dat waar we min of meer iets kunnen bij voorstellen, andere kenmerken die we in dit hoofdstuk zullen bekomen zullen moeilijker te interpreteren zijn.\n",
    "\n",
    "Andere mogelijkheden zijn bijvoorbeeld dat we over een variabele verschillende metingen hebben en we vervangen deze metingen door telkens het gemiddelde te nemen.\n",
    "\n",
    "#### PCA\n",
    "\n",
    "![PCA ](~/Desktop/datascience/images/GS.png)\n",
    "\n",
    "\n",
    "Hierboven wordt het verband tussen 2 kenmerken getoond. We zien dat indien we de X en Y-as keren en de assen leggen volgens de 2 pijlen in de wolk. We merken dat langs de lange as 1 kenmerk de meeste variantie verklaart. Dit kenmerk behouden we het andere kenmerk kunnen we droppen.\n",
    "\n",
    "Voor we de techniek van Principal Component Analysis toepassen, zorgen we er voor dat we de gegevens standarizeren.\n",
    "\n",
    "In python:\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "data_std=pd.DataFrame(scaler.fit_transform(data),columns=data.columns)\n",
    "\n",
    "We kunnen nu de getransformeerde data_std verder transformeren m.b.v. PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA()\n",
    "print(pca.fit_transform(data_std))\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "om de totale variantie te bekijken gebruiken we:\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "\n",
    "Aangezien we steeds de gegevens steeds standariseren voordat we pca toepassen kunnen we dit samen met de analyse die we willen toepassen in een pijplijn plaatsen.\n",
    "Zoals bijvoorbeeld:\n",
    "\n",
    "pipe = Pipeline([\n",
    "('scaler'\n",
    ", StandardScaler()),\n",
    "('pcareducer'\n",
    ", PCA(n_components=4)),\n",
    "('classifier'\n",
    ", RandomForestClassifier())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(pipe.steps[1])\n",
    "pipe.steps[1][1].explained_variance_ratio_.cumsum()\n",
    "print(pipe.score(X_test, y_test))\n",
    "\n",
    "Bij de parameter n_components kan men ook een waarde tussen 0 en 1 plaatsen. Bijvoorbeeld 0.9 in dit geval gaat PCA zoveel componenten behouden tot hij minstens 90% van de variatie kan verklaren.\n",
    "\n",
    "Wat is nu een goede trade-off tussen verklaarde variantie en aantal componenten. We kunnen op de Y-as de verklaarde variantie en op de X-as het aantal behouden componenten uitzetten.\n",
    "![Explained Variance](~/Desktop/datascience/images/explvar.png)\n",
    "\n",
    "\n",
    "We zien hier dat de variantie sterk daalt tot 3. We zitten als het ware in de knik van de elleboog dicht bij de ideale verhouding tussen weinig componenten en veel verklaarde variantie.\n",
    "\n",
    "\n",
    "[id]: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006907\n",
    "\n",
    "[id] https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net\n",
    "\n",
    "[id3] https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.XlwKt5NKiWY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variabelen zonder invloed\n",
    "\n",
    "Wanneer weten we dat een variabele geen invloed zal hebben op onze doelvector y? \n",
    "\n",
    "* Als de waarde voor iedere waarneming dezelfde is\n",
    "* Als de waarde voor iedere waarneming onbekend is\n",
    "\n",
    "\n",
    "Hoe kunnen we dit zien?\n",
    "\n",
    "#### Als de waarde voor iedere waarneming dezelfde is\n",
    "\n",
    "Voor numerieke gegevens is dit gemakkelijk te achterhalen \n",
    "als voor variabele a std(a)=0 dan is a constant.\n",
    "\n",
    "df.describe() geeft van ieder variabele de mean,std,...\n",
    "als dus std =0 dan kunnen we deze variabele droppen uit de dataframe.\n",
    "\n",
    "Voor niet numerieke waarden zoals categoriën. Kunnen wse dit op^merken door van deze gegevens een hsitogram af te drukken.\n",
    "\n",
    "#### Als de waarde voor iedere waarneming onbekend is\n",
    "\n",
    "df.isna().sum() geeft voor iedere kolom in df het aantal waarden waarvoor er geen waarde is gedefinieerd.\n",
    "\n",
    "#### Wat als bijna aan beide voorwaarden is voldaan?\n",
    "\n",
    "Indien aan 1 of beide voorwaarden bijna voldaan is dan zullen we zelf moeten beoordelen of we de variabele verwijderen of niet.\n",
    "\n",
    "### Gecorreleerde variabelen\n",
    "\n",
    "Een andere reden om variabele te verwijderen is correlatie. Bijvoorbeeld stel dat we het gewicht in kg en  het gewicht in ponden hebben van een persoon. Uiteraard zal een variabele voldoende zijn en zal men 1 van de 2 mogen schrappen.\n",
    "\n",
    "Nu hoef de correlatie niet zo sterk te zijn als hierboven maar gaat men bij 2 sterk gecorreleerde gegevens met een correlatie coefficient r waarvoor geldt dat abs(r) bijna 1, één van de twee verwijderen. \n",
    "\n",
    "### Hoe Train-test-split gebruiken?\n",
    "\n",
    "Bij iedere analyse zullen we de dataset opsplitsen in een gedeelte om ons model te trainen (X_train en Y_train) en een ander deel gebruiken we om te kijken hoe goed ons model het doet op nieuwe data (X_test en y_test of test data)\n",
    "\n",
    "Indien de y waarden bestaan uit slechts 2 labels bijvoorbeeld 'ja' en 'neen' dan willen we in de training en de test data dezelfde verhouding terug zien van 'ja' en 'neen' waarden. Dit noemen we gestratifieerd splitsen. Door de volgende instructie zorgt Python dat de y_test en y_train data dus een zelfde verhouding aan 'ja/neen' waarden hebben.\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, stratify=y)\n",
    "\n",
    "### Normalisatie en standarisatie van de gegevens\n",
    "\n",
    "#### Standarddeviatie op 1 zetten en gemiddelde op nul\n",
    "\n",
    "Het kan voor veel analyses die we op de data willen loslaten een voordeel zijn dat de gegevens allemaal gemiddelde nul hebben en standaardafwijking 1. De StandardScaler is de klasse die methodes heeft om dit voor ieder numeriek kenmerk te bewerkstelligen. Het is een klasse die behoort tot  sklearn.preprocessing.\n",
    "\n",
    "\n",
    "#### Log normalizatie\n",
    "\n",
    "Door de natuurlijke logaritme te nemen van een getal kunnen we de variantie van de gegevens sterk verminderen. Opgepast we kunnen dit enkel toepassen op positieve getallen.\n",
    "\n",
    "#### Niet-numerieke gegevens preprocessen.\n",
    "\n",
    "Niet numerieke gegevens zoals tekst willen we graag toch omzetten in numerieke waarden, omdat we dan meer tools kunnen gebruiken om deze gegevens te verwerken.\n",
    "\n",
    "Dit kan gebeuren op verschillende manieren\n",
    "\n",
    "Bijvoorbeeld:\n",
    "\n",
    "Stel dat we dataframe hebben met daarin verschillende kleuren.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Regularisatie\n",
    "\n",
    "### LogisticRegression and RFE\n",
    "\n",
    "### RandomForestClassifier and RFE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Lasso\n",
    "\n",
    "Lasso (Least Absolute Shrinkage and Selection Operator) bespreken. \n",
    "Voor welke alpha is de R^2 optimaal?\n",
    "Zoek evenwicht tussen aantal variabelen en score!\n",
    "\n",
    "LassoCv laat toe om automatisch optimale alpha te bepalen\n",
    "\n",
    "### Elastic Net\n",
    "\n",
    "Probeert nadaelen van Lasso op te heffen. Welke zijn dit?\n",
    "\n",
    "### Wegstemmen van variabelen\n",
    "Met RandomForestRegression\n",
    "Lasso\n",
    "SGRegressor kunnen we variabele selecteren die in de 3 modellen van belang zijn. Wat is de performantie?\n",
    "\n",
    "\n",
    "### Kenmerken extractie (Feature extraction)\n",
    "\n",
    "I.p.v. kenmerken te schrappen kunnen we ook kenmerken combineren.\n",
    "\n",
    "Bijvoorbeeld indien we het kenmerk zwaarlijvigheid willen gebruiken bij het analyseren van de gegevens. Kunnen we de kenmerken lichaamslengte en gewicht combineren in de BMI.\n",
    "\n",
    "De BMI is een kenmerk dat waar we min of meer iets kunnen bij voorstellen, andere kenmerken die we in dit hoofdstuk zullen bekomen zullen moeilijker te interpreteren zijn.\n",
    "\n",
    "Andere mogelijkheden zijn bijvoorbeeld dat we over een variabele verschillende metingen hebben en we vervangen deze metingen door telkens het gemiddelde te nemen.\n",
    "\n",
    "#### PCA\n",
    "\n",
    "![PCA ](~/Desktop/datascience/images/GS.png)\n",
    "\n",
    "\n",
    "Hierboven wordt het verband tussen 2 kenmerken getoond. We zien dat indien we de X en Y-as keren en de assen leggen volgens de 2 pijlen in de wolk. We merken dat langs de lange as 1 kenmerk de meeste variantie verklaart. Dit kenmerk behouden we het andere kenmerk kunnen we droppen.\n",
    "\n",
    "Voor we de techniek van Principal Component Analysis toepassen, zorgen we er voor dat we de gegevens standarizeren.\n",
    "\n",
    "In python:\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "data_std=pd.DataFrame(scaler.fit_transform(data),columns=data.columns)\n",
    "\n",
    "We kunnen nu de getransformeerde data_std verder transformeren m.b.v. PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA()\n",
    "print(pca.fit_transform(data_std))\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "om de totale variantie te bekijken gebruiken we:\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "\n",
    "Aangezien we steeds de gegevens steeds standariseren voordat we pca toepassen kunnen we dit samen met de analyse die we willen toepassen in een pijplijn plaatsen.\n",
    "Zoals bijvoorbeeld:\n",
    "\n",
    "pipe = Pipeline([\n",
    "('scaler'\n",
    ", StandardScaler()),\n",
    "('pcareducer'\n",
    ", PCA(n_components=4)),\n",
    "('classifier'\n",
    ", RandomForestClassifier())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(pipe.steps[1])\n",
    "pipe.steps[1][1].explained_variance_ratio_.cumsum()\n",
    "print(pipe.score(X_test, y_test))\n",
    "\n",
    "Bij de parameter n_components kan men ook een waarde tussen 0 en 1 plaatsen. Bijvoorbeeld 0.9 in dit geval gaat PCA zoveel componenten behouden tot hij minstens 90% van de variatie kan verklaren.\n",
    "\n",
    "Wat is nu een goede trade-off tussen verklaarde variantie en aantal componenten. We kunnen op de Y-as de verklaarde variantie en op de X-as het aantal behouden componenten uitzetten.\n",
    "![Explained Variance](~/Desktop/datascience/images/explvar.png)\n",
    "\n",
    "\n",
    "We zien hier dat de variantie sterk daalt tot 3. We zitten als het ware in de knik van de elleboog dicht bij de ideale verhouding tussen weinig componenten en veel verklaarde variantie.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[id]: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006907\n",
    "\n",
    "[id] https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net\n",
    "\n",
    "[id3] https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.XlwKt5NKiWY\n",
    "\n",
    "[id4] https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
